{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该notebook为指导在树算法中实现一些额外的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth\n",
    "```max_depth```参数是控制树生成的最重要的参数之一。在递归生成树时没想到什么好办法可以直接获取当前树的深度，不过可以通过增加一个叶子节点数的全局变量来获取当前树的深度，原理在于深度为$d$的树，他的最小叶子节点数与最大叶子节点数是可以通过公式算出来的。以下代码全部引自之前的notebook，不再赘述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "# data=load_breast_cancer()\n",
    "# X,Y=data.data,data.target\n",
    "# del data\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "# training_data=np.c_[X_train,Y_train]\n",
    "# testing_data=np.c_[X_test,Y_test]\n",
    "\n",
    "# def Gini(data, y_idx=-1):\n",
    "#     K = np.unique(data[:, y_idx])\n",
    "#     n_sample = len(data)\n",
    "#     gini_idx = 1 - \\\n",
    "#         np.sum([np.square(len(data[data[:, y_idx] == k])/n_sample) for k in K])\n",
    "\n",
    "#     return gini_idx\n",
    "\n",
    "# def BinSplitData(data,f_idx,f_val):\n",
    "#     data_left=data[data[:,f_idx]<=f_val]\n",
    "#     data_right=data[data[:,f_idx]>f_val]\n",
    "#     return data_left,data_right\n",
    "\n",
    "# from scipy import stats\n",
    "\n",
    "# def Test(data, criteria='gini', min_samples_split=5, min_samples_leaf=5, min_impurity_decrease=0.0):\n",
    "#     n_sample, n_feature = data.shape\n",
    "\n",
    "#     if n_sample < min_samples_split or len(np.unique(data[:,-1]))==1:\n",
    "#         return None, stats.mode(data[:, -1])[0][0]\n",
    "\n",
    "#     Gini_before = Gini(data)\n",
    "#     best_gain = 0\n",
    "#     best_f_idx = None\n",
    "#     best_f_val = stats.mode(data[:, -1])[0][0]\n",
    "\n",
    "#     for f_idx in range(n_feature-1):\n",
    "#         for f_val in np.unique(data[:, f_idx]):\n",
    "#             data_left, data_right = BinSplitData(data, f_idx, f_val)\n",
    "\n",
    "#             if len(data_left) < min_samples_leaf or len(data_right) < min_samples_leaf:\n",
    "#                 continue\n",
    "\n",
    "#             Gini_after = len(data_left)/n_sample*Gini(data_left) + \\\n",
    "#                 len(data_right)/n_sample*Gini(data_right)\n",
    "#             gain = Gini_before-Gini_after \n",
    "\n",
    "#             if gain < min_impurity_decrease or gain < best_gain:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 best_gain = gain\n",
    "#                 best_f_idx, best_f_val = f_idx, f_val\n",
    "\n",
    "#     return best_f_idx, best_f_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在递归生成树的函数之前增加一个全局变量：```nodes```，用于实时监控CART树的叶节点数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cut_f': 23, 'cut_val': 880.8, 'left': 1.0, 'right': 0.0} 3\n"
     ]
    }
   ],
   "source": [
    "# nodes=0\n",
    "# max_depth=1\n",
    "\n",
    "# def CART(data,criteria='gini',min_samples_split=5,min_samples_leaf=5,min_impurity_decrease=0.0):\n",
    "#     best_f_idx,best_f_val=Test(data,criteria,min_samples_split,min_samples_leaf,min_impurity_decrease)\n",
    "    \n",
    "#     tree={}\n",
    "#     tree['cut_f']=best_f_idx\n",
    "#     tree['cut_val']=best_f_val\n",
    "    \n",
    "#     nonlocal nodes\n",
    "#     nodes+=1\n",
    "    \n",
    "#     if best_f_idx==None:\n",
    "#         return best_f_val\n",
    "    \n",
    "#     # 节点数超过最大深度的限制，也要返回叶节点，叶节点的值为当前数据中的目标值众数\n",
    "#     if nodes>=2**max_depth:\n",
    "#         return stats.mode(data[:, -1])[0][0]\n",
    "    \n",
    "#     data_left,data_right=BinSplitData(data,best_f_idx,best_f_val)\n",
    "#     tree['left']=CART(data_left,criteria,min_samples_split,min_samples_leaf,min_impurity_decrease)\n",
    "#     tree['right']=CART(data_right,criteria,min_samples_split,min_samples_leaf,min_impurity_decrease)\n",
    "    \n",
    "#     return tree\n",
    "\n",
    "# tree=CART(training_data)\n",
    "\n",
    "# # CART树存储为字典形式，将其字符串化后，每一个'left'代表左叉树枝，每一个'right'代表右叉树枝\n",
    "# # 节点数之和等于树枝数+1\n",
    "# tree_str=str(tree)\n",
    "# edge=tree_str.count('left')+tree_str.count('right')\n",
    "# assert edge+1==nodes\n",
    "\n",
    "# print(tree,nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample_weight\n",
    "该参数用于控制样本在树的分裂时所占的权重，实质就是不同样本对于纯净度的贡献。因为sklearn中该参数是在```fit```方法中，所以实现该参数需要结合```.py```工程文件来分析。\n",
    "\n",
    "```DecisionTreeClassifier.py```中的```fit```方法只有两步：\n",
    "1. 将```X_train```与```Y_train```拼接起来便于共同操作\n",
    "2. 递归调用```CART```方法\n",
    "而```CART```方法中又调用了```Test```方法与```BinSplitData```方法，所以需要修改的部分就是这四个方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data=load_breast_cancer()\n",
    "X,Y=data.data,data.target\n",
    "del data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "training_data=np.c_[X_train,Y_train]\n",
    "testing_data=np.c_[X_test,Y_test]\n",
    "\n",
    "def Gini(data, y_idx=-1):\n",
    "    K = np.unique(data[:, y_idx])\n",
    "    n_sample = len(data)\n",
    "    gini_idx = 1 - \\\n",
    "        np.sum([np.square(len(data[data[:, y_idx] == k])/n_sample) for k in K])\n",
    "\n",
    "    return gini_idx\n",
    "\n",
    "def BinSplitData(data,f_idx,f_val):\n",
    "    data_left=data[data[:,f_idx]<=f_val]\n",
    "    data_right=data[data[:,f_idx]>f_val]\n",
    "    return data_left,data_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然样本权重是为纯净度提供贡献，那么需要更改的代码就在```Test```函数里面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def Test(data, criteria='gini', min_samples_split=5, min_samples_leaf=5, min_impurity_decrease=0.0):\n",
    "    '''\n",
    "    对数据做test，找到最佳分割特征与特征值\n",
    "    return: best_f_idx, best_f_val，前者为空时代表叶节点，两者都为空时说明无法分裂\n",
    "    min_samples_split: 分裂所需的最小样本数，大于1\n",
    "    min_samples_leaf: 叶子节点的最小样本数，大于0\n",
    "    min_impurity_decrease: 分裂需要满足的最小增益\n",
    "    '''\n",
    "    n_sample, n_feature = data.shape\n",
    "\n",
    "    # 数据量小于阈值则直接返回叶节点，数据已纯净也返回叶节点\n",
    "    if n_sample < min_samples_split or len(np.unique(data[:,-1]))==1:\n",
    "        # 注意这里与回归树不同，回归树返回均值，分类树返回众数\n",
    "        return None, stats.mode(data[:, -1])[0][0]\n",
    "\n",
    "    Gini_before = Gini(data)    # 分裂前的Gini\n",
    "    best_gain = 0\n",
    "    best_f_idx = None\n",
    "    best_f_val = stats.mode(data[:, -1])[0][0]    # 默认分割值设为目标众数，当找不到分割点时返回该值作为叶节点\n",
    "\n",
    "    # 遍历所有特征与特征值\n",
    "    for f_idx in range(n_feature-1):\n",
    "        for f_val in np.unique(data[:, f_idx]):\n",
    "            data_left, data_right = BinSplitData(data, f_idx, f_val)    # 二分数据\n",
    "\n",
    "            # 分割后的分支样本数小于阈值则放弃分裂\n",
    "            if len(data_left) < min_samples_leaf or len(data_right) < min_samples_leaf:\n",
    "                continue\n",
    "\n",
    "            # 分割后的加权Gini\n",
    "            Gini_after = len(data_left)/n_sample*Gini(data_left) + \\\n",
    "                len(data_right)/n_sample*Gini(data_right)\n",
    "            gain = Gini_before-Gini_after    # Gini的减小量为增益\n",
    "\n",
    "            # 分裂后的增益小于阈值或小于目前最大增益则放弃分裂\n",
    "            if gain < min_impurity_decrease or gain < best_gain:\n",
    "                continue\n",
    "            else:\n",
    "                # 否则更新最大增益\n",
    "                best_gain = gain\n",
    "                best_f_idx, best_f_val = f_idx, f_val\n",
    "\n",
    "    # 返回一个最佳分割特征与最佳分割点，注意会有空的情况\n",
    "    return best_f_idx, best_f_val"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
